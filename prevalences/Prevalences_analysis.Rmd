---
title: "Generalized Linear Mixed Models for Prevalences"
date: "2025-07-20"
output:
  html_document:
    toc: true
    toc_float: true
    theme: flatly
    toc_depth: 4
    number_sections: true
    code_folding: hide
  word_document:
    toc: true
    toc_depth: '4'
  pdf_document:
    toc: true
    toc_depth: '4'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = TRUE, message = FALSE, cache = FALSE)

# Set the root directory for the entire document (recommended way)
knitr::opts_knit$set(root.dir = dirname(rstudioapi::getActiveDocumentContext()$path))

```

# Preparation

```{r load-packages}
library(readr)
library(metafor)
library(lme4)
library(influence.ME)
library(dplyr)
library(gt)
library(purrr)
library(tidyr)
```

## Load Data

```{r load-data}
# load data
df_moderation <- read.csv2("../pre-processing/output/data_for_moderation_analyses.csv", dec = ".")

# Display the first rows to check the data
head(df_moderation)
```

## Descriptive Statistics

We provide basic descriptive statistics of the included studies, without excluding any data due to missingness.

```{r descriptives}
# Calculate descriptives
total_number_of_samples <- nrow(df_moderation)
total_sample_size <- sum(df_moderation$Sample_Size, na.rm = TRUE)

# Create a summary table
summary_table <- data.frame(
  Description = c("Number of studies / cohorts", "Total sample size (sum of available Sample_Size)"),
  Value = format(c(total_number_of_samples, total_sample_size), big.mark = ",")
)

# Display as a table
knitr::kable(summary_table, caption = "Descriptive Statistics of the Dataset")
```

### Descriptives Tables for All Studies

```{r descriptives-studies-table}
overview <- tibble(
  `Authors (Study)` = df_moderation$Study,
  `Sample Size`     = df_moderation$Sample_Size,
  `Mean Age`        = df_moderation$Mean_age,
  `Percentage Women`= df_moderation$Percentage_women,
  `Assessed Trauma Type` = df_moderation$Assessed_trauma_type,
  `Number of TP assessments`  = df_moderation$TP_assessments,
  `Number of Trajectories Found` = df_moderation$N_trajectories

  ) |> 
  arrange(`Authors (Study)`)

if (knitr::is_html_output() || knitr::is_latex_output()) {
  fmt <- if (knitr::is_latex_output()) "latex" else "html"

  overview %>%
    mutate(
      `Sample Size` = format(`Sample Size`, big.mark = ",", trim = TRUE),
      `Mean Age` = ifelse(is.na(`Mean Age`), NA, sprintf("%.1f", `Mean Age`)),
      `Percentage Women` = ifelse(is.na(`Percentage Women`), NA, sprintf("%.1f%%", `Percentage Women`))
    ) |>
    knitr::kable(format = fmt, caption = "Study Overview", booktabs = TRUE, linesep = "") |>
    kableExtra::kable_styling(full_width = FALSE, position = "left",
                              bootstrap_options = c("striped", "hover", "condensed")) |>
    kableExtra::column_spec(1, bold = TRUE) |>
    kableExtra::scroll_box(height = "470px")
}
```
# Prevalences

```{r portable-glmm-function}
# Portable function for pooled prevalence via GLMM with continuity correction
fit_glmm_prev <- function(df, event_col, n_col = "Sample_Size", label = event_col) {
  xi <- suppressWarnings(as.numeric(df[[event_col]]))
  ni <- suppressWarnings(as.numeric(df[[n_col]]))

  extreme <- !is.na(xi) & !is.na(ni) & (xi == 0 | xi == ni)
  xi[extreme] <- xi[extreme] + 0.5
  ni[extreme] <- ni[extreme] + 1

  fit <- metafor::rma.glmm(measure = "PLO", xi = xi, ni = ni, data = df)
  pr  <- predict(fit, transf = metafor::transf.ilogit)

  data.frame(
    Analysis        = label,
    Pooled_Prevalence = round(as.numeric(pr$pred), 3),
    CI_Lower          = round(as.numeric(pr$ci.lb), 3),
    CI_Upper          = round(as.numeric(pr$ci.ub), 3),
    Samples_included  = fit$k,
    Logit_Estimate    = round(unname(coef(fit)[1]), 3),
    τ2                = round(as.numeric(fit$tau2), 3),
    check.names = FALSE
  )
}
```

## 🚀 Low Symptom Trajectory

### Descriptives

We provide additional descriptives based on the Low trajectory variable, using the full dataset.

```{r Low-descriptives}
# Copy the dataset to avoid overwriting the original
df_low <- df_moderation

# Ensure Low_percentage is numeric
df_low$Low_percentage <- as.numeric(df_low$Low_percentage)

# Calculate Low_n as (percentage / 100) * sample size
df_low$Low_n <- round((df_low$Low_percentage / 100) * df_low$Sample_Size)

# Total number of individuals classified as Low (ignoring missingness in other variables)
total_Low_n <- sum(df_low$Low_n, na.rm = TRUE)

# Number of unique samples (assumes a column Study exists)
unique_Low_studies <- length(unique(df_low$Study[!is.na(df_low$Low_percentage)]))

# Display as a table
additional_info <- data.frame(
  Description = c("Total number of individuals in Low trajectory", "Number of unique studies"),
  Value = format(c(total_Low_n, unique_Low_studies), big.mark = ",")
)

knitr::kable(additional_info, caption = "Additional Descriptives for Low Trajectory Analysis")
```

### Generic GLMM results

We estimate the pooled prevalence of the **Low trajectory** using a Generalized Linear Mixed Model (GLMM).\
We apply a continuity correction of 0.5 individuals for studies reporting exactly 0% or 100% Low cases.\
No data is removed from the dataset; the `rma.glmm()` function handles missingness internally.

```{r Low-glmm}
# Fit GLMM
glmm_Low <- fit_glmm_prev(df_low, event_col = "Low_n", n_col = "Sample_Size",
                             label = "Main Analysis")

# Display result
knitr::kable(glmm_Low, caption = "Pooled Prevalence Estimate for Low Trajectory (GLMM)")
```

### Sensitivity Analysis 1

Excluding samples with Low trajectory ≥90% of the sample

```{r Low-sensitivity_1}
# Subset: Exclude samples with Low trajectory ≥90% of the sample
df_low_sens1 <- subset(df_low,
                   !is.na(Low_n) & !is.na(Sample_Size) &
                   !is.na(Low_percentage) & Low_percentage < 90)

# Fit GLMM
glmm_Low_sens1 <-  fit_glmm_prev(df_low_sens1, "Low_n", "Sample_Size", "Sensitivity 1: Exclude ≥90% Low")

# Display table
knitr::kable(glmm_Low_sens1, caption = "Sensitivity Analysis 1: Low Trajectory (Excl. ≥90% Prevalence)")
```

### Sensitivity Analysis 2

Including only large samples (N \> 999)

```{r Low-sensitivity-2}
# Subset: Include only samples with Sample_Size > 999
df_low_sens2 <- subset(df_low,
                   !is.na(Low_n) & !is.na(Sample_Size) &
                   Sample_Size > 999)

# Fit GLMM
glmm_Low_sens2 <- fit_glmm_prev(df_low_sens2, "Low_n", "Sample_Size", "Sensitivity 2: N > 999")

# Display table
knitr::kable(glmm_Low_sens2, caption = "Sensitivity Analysis 2: Low Trajectory (Samples > 999)")
```

### Sensitivity Analysis 3

Exclude Influential Studies: We conducted an influence analysis to identify studies with disproportionate impact on the pooled estimate using Cook's distance from a glmer model.

```{r Low-influential}
# Fit a GLMM with glmer (binomial model with random study effect)
model_glmer_Low <- glmer(cbind(round(Low_n), Sample_Size - round(Low_n)) ~ 1 + (1 | Study),
                     data = df_low,
                     family = binomial)

# Run influence analysis by Studies
infl <- influence(model_glmer_Low, group = "Study")

# Compute Cook's distance
cooks <- cooks.distance(infl)

# Define rule-of-thumb threshold
threshold <- 4 / length(cooks)

# Plot Cook's distances
p1 <- plot(cooks, type = "h", lwd = 2,
     main = "Cook's Distance per Study",
     ylab = "Cook's Distance", xlab = "Study Index")
abline(h = threshold, col = "red", lty = 2)

# Identify studies above the threshold
influential_indices <- which(cooks > threshold)
influential_studies_Low <- unique(df_low$Study[influential_indices])

# Display studies
influential_table <- data.frame(
  Study_ID = influential_studies_Low,
  Cooks_Distance = round(cooks[influential_indices], 3)
)

knitr::kable(influential_table, caption = "Studies Identified as Influential (Cook's Distance)")
```

We reran the GLMM excluding the identified influential studies.

```{r Low-sens-influential}
# Exclude the influential studies
df_Low_noinf <- df_low %>%
  filter(!Study %in% influential_studies_Low)

# Refit GLMM (metafor version)
glmm_Low_noinf <- fit_glmm_prev(df_Low_noinf, "Low_n", "Sample_Size",
                           "Sensitivity 3: Excluding Influential Studies")

# Display table
knitr::kable(glmm_Low_noinf, caption = "Sensitivity Analysis 3: Low Trajectory (Excluding Influential Studies)")
```

### Use `glmer` estimate

with the glmer\`-based intercept estimate:

```{r Low-glmer-summary}
# Extract fixed effect estimate
est_glmer_Low <- fixef(model_glmer_Low)["(Intercept)"]
se_glmer_Low <- sqrt(vcov(model_glmer_Low)["(Intercept)", "(Intercept)"])

# Compute 95% CI (logit scale)
ci_lower_glmer_Low <- est_glmer_Low - 1.96 * se_glmer_Low
ci_upper_glmer_Low <- est_glmer_Low + 1.96 * se_glmer_Low

n_glmer_studies_Low <- length(ranef(model_glmer_Low)$Study[[1]])

# Run glmer
glmer_summary_Low <- data.frame(
  Model = "glmer (binomial, random intercept)",
  Pooled_Prevalence = round(plogis(est_glmer_Low), 3),
  CI_Lower = round(plogis(ci_lower_glmer_Low), 3),
  CI_Upper = round(plogis(ci_upper_glmer_Low), 3), 
  Studies_included = n_glmer_studies_Low
)

knitr::kable(glmer_summary_Low, caption = "Low Trajectory Estimate from glmer Model")
```

**Note on Number of Studies Included** The number of studies included in the models may differ between rma.glmm() and glmer(). This is expected because the two methods handle data slightly differently:

rma.glmm() is designed for meta-analysis and accepts aggregated data (events + sample size). It applies continuity corrections directly and may include more studies when appropriate.

glmer() is a general GLMM function. It uses binomial counts and handles missingness or zero counts differently. Studies with no variance or missing outcomes may be excluded automatically.

Both approaches are valid, but they may produce slightly different sample sizes. We report both transparently for completeness.

## 🌿 Decreasing Symptoms Trajectory

We estimate the pooled prevalence of the Decreasing trajectory using a Generalized Linear Mixed Model (GLMM).

### Descriptives

```{r Decreasing-descriptives}
# Copy the dataset to avoid overwriting the original
df_Decreasing <- df_moderation

# Ensure Decreasing_percentage is numeric
df_Decreasing$Decreasing_percentage <- as.numeric(df_Decreasing$Decreasing_percentage)


# Calculate Decreasing_n as (percentage / 100) * sample size
df_Decreasing$Decreasing_n <- round((df_Decreasing$Decreasing_percentage / 100) * df_Decreasing$Sample_Size)

# Total number of individuals classified as Decreasing (ignoring missingness in other variables)
total_Decreasing_n <- sum(df_Decreasing$Decreasing_n, na.rm = TRUE)

# Number of unique samples (assumes a column Study exists)
unique_Decreasing_studies <- length(unique(df_Decreasing$Study[!is.na(df_Decreasing$Decreasing_percentage)]))

# Display as a table
additional_info <- data.frame(
  Description = c("Total number of individuals in Decreasing trajectory", "Number of unique studies"),
  Value = format(c(total_Decreasing_n, unique_Decreasing_studies), big.mark = ",")
)

knitr::kable(additional_info, caption = "Additional Descriptives for Decreasing Trajectory Analysis")
```

### Generic GLMM

```{r Decreasing-glmm}
# Fit GLMM
glmm_Decreasing <- fit_glmm_prev(df_Decreasing, event_col = "Decreasing_n", n_col = "Sample_Size",
                             label = "Main Analysis")

# Display result
knitr::kable(glmm_Decreasing, caption = "Pooled Prevalence Estimate for Decreasing Trajectory (GLMM)")
```

### Sensitivity Analysis 1

Exclude samples ≥90% Decreasing Proportions

```{r Decreasing-sens1}
# Subset: Exclude samples with Decreasing trajectory ≥90% of the sample
df_Decreasing_sens1 <- subset(df_Decreasing,
                   !is.na(Decreasing_n) & !is.na(Sample_Size) &
                   !is.na(Decreasing_percentage) & Decreasing_percentage < 90)

# Fit GLMM
glmm_Decreasing_sens1 <-  fit_glmm_prev(df_Decreasing_sens1, "Decreasing_n", "Sample_Size", "Sensitivity 1: Exclude ≥90% Decreasing")

# Display table
knitr::kable(glmm_Decreasing_sens1, caption = "Sensitivity Analysis 1: Decreasing Trajectory (Excl. ≥90% Prevalence)")
```

### Sensitivity Analysis 2

Include Only Samples with N \> 999

```{r Decreasing-sens2}
# Subset: Include only samples with Sample_Size > 999
df_Decreasing_sens2 <- subset(df_Decreasing,
                   !is.na(Decreasing_n) & !is.na(Sample_Size) &
                   Sample_Size > 999)

# Fit GLMM
glmm_Decreasing_sens2 <- fit_glmm_prev(df_Decreasing_sens2, "Decreasing_n", "Sample_Size", "Sensitivity 2: N > 999")

# Display table
knitr::kable(glmm_Decreasing_sens2, caption = "Sensitivity Analysis 2: Decreasing Trajectory (Samples > 999)")
```

### Sensitivity Analysis 3

Exclude Influential Studies

```{r Decreasing-influential}
# Fit a GLMM with glmer (binomial model with random study effect)
model_glmer_Decreasing <- glmer(cbind(round(Decreasing_n), Sample_Size - round(Decreasing_n)) ~ 1 + (1 | Study),
                     data = df_Decreasing,
                     family = binomial)

# Run influence analysis by Studies
infl <- influence(model_glmer_Decreasing, group = "Study")

# Compute Cook's distance
cooks <- cooks.distance(infl)

# Define rule-of-thumb threshold
threshold <- 4 / length(cooks)

# Plot Cook's distances
p1 <- plot(cooks, type = "h", lwd = 2,
     main = "Cook's Distance per Study",
     ylab = "Cook's Distance", xlab = "Study Index")
abline(h = threshold, col = "red", lty = 2)

# Identify studies above the threshold
influential_indices <- which(cooks > threshold)
influential_studies_Decreasing <- unique(df_Decreasing$Study[influential_indices])

# Display studies
influential_table <- data.frame(
  Study_ID = influential_studies_Decreasing,
  Cooks_Distance = round(cooks[influential_indices], 3)
)

knitr::kable(influential_table, caption = "Studies Identified as Influential (Cook's Distance)")
```

Exclude Influential Studies

```{r Decreasing-sens-infl}
# Exclude the influential studies
df_Decreasing_noinf <- df_Decreasing %>%
  filter(!Study %in% influential_studies_Decreasing)

# Refit GLMM
glmm_Decreasing_noinf <- fit_glmm_prev(df_Decreasing_noinf, "Decreasing_n", "Sample_Size",
                           "Sensitivity 3: Excluding Influential Studies")

# Display table
knitr::kable(glmm_Decreasing_noinf, caption = "Sensitivity Analysis 3: Decreasing Trajectory (Excluding Influential Studies)")
```

### Use `glmer` estimate

Use with the glmer\`-based intercept estimate:

```{r Decreasing-glmer-summary}
# Extract fixed effect estimate
est_glmer_Decreasing <- fixef(model_glmer_Decreasing)["(Intercept)"]
se_glmer_Decreasing <- sqrt(vcov(model_glmer_Decreasing)["(Intercept)", "(Intercept)"])

# Compute 95% CI (logit scale)
ci_Lower_glmer_Decreasing <- est_glmer_Decreasing - 1.96 * se_glmer_Decreasing
ci_upper_glmer_Decreasing <- est_glmer_Decreasing + 1.96 * se_glmer_Decreasing

n_glmer_studies_Decreasing <- length(ranef(model_glmer_Decreasing)$Study[[1]])

# Run glmer
glmer_summary_Decreasing <- data.frame(
  Model = "glmer (binomial, random intercept)",
  Pooled_Prevalence = round(plogis(est_glmer_Decreasing), 3),
  ci_Lower = round(plogis(ci_Lower_glmer_Decreasing), 3),
  CI_Upper = round(plogis(ci_upper_glmer_Decreasing), 3), 
  Studies_included = n_glmer_studies_Decreasing
)

knitr::kable(glmer_summary_Decreasing, caption = "Decreasing Trajectory Estimate from glmer Model")
```

## ⚠️ Increasing Symptoms Trajectory

We estimate the pooled prevalence of the Increasing trajectory using a Generalized Linear Mixed Model (GLMM).

### Descriptives

```{r Increasing-descriptives}
# Copy the dataset to avoid overwriting the original
df_Increasing <- df_moderation

# Ensure Increasing_percentage is numeric
df_Increasing$Increasing_percentage <- as.numeric(df_Increasing$Increasing_percentage)

# Calculate Increasing_n as (percentage / 100) * sample size
df_Increasing$Increasing_n <- round((df_Increasing$Increasing_percentage / 100) * df_Increasing$Sample_Size)

# Total number of individuals classified as Increasing (ignoring missingness in other variables)
total_Increasing_n <- sum(df_Increasing$Increasing_n, na.rm = TRUE)

# Number of unique samples (assumes a column Study exists)
unique_Increasing_studies <- length(unique(df_Increasing$Study[!is.na(df_Increasing$Increasing_percentage)]))

# Display as a table
additional_info <- data.frame(
  Description = c("Total number of individuals in Increasing trajectory", "Number of unique studies"),
  Value = format(c(total_Increasing_n, unique_Increasing_studies), big.mark = ",")
)

knitr::kable(additional_info, caption = "Additional Descriptives for Increasing Trajectory Analysis")
```

### Generic GLMM

```{r Increasing-glmm}
# Fit GLMM
glmm_Increasing <- fit_glmm_prev(df_Increasing, event_col = "Increasing_n", n_col = "Sample_Size",
                             label = "Main Analysis")

# Display result
knitr::kable(glmm_Increasing, caption = "Pooled Prevalence Estimate for Increasing Trajectory (GLMM)")
```

### Sensitivity Analysis 1

Exclude Samples with ≥90% Decreasing Proportions

```{r Increasing-sens1}
# Subset: Exclude samples with Increasing trajectory ≥90% of the sample
df_Increasing_sens1 <- subset(df_Increasing,
                   !is.na(Increasing_n) & !is.na(Sample_Size) &
                   !is.na(Increasing_percentage) & Increasing_percentage < 90)

# Fit GLMM
glmm_Increasing_sens1 <-  fit_glmm_prev(df_Increasing_sens1, "Increasing_n", "Sample_Size", "Sensitivity 1: Exclude ≥90% Increasing")

# Display table
knitr::kable(glmm_Increasing_sens1, caption = "Sensitivity Analysis 1: Increasing Trajectory (Excl. ≥90% Prevalence)")
```

### Sensitivity Analysis 2

Include Only Samples with N \> 999

```{r Increasing-sens2}
# Subset: Include only samples with Sample_Size > 999
df_Increasing_sens2 <- subset(df_Increasing,
                   !is.na(Increasing_n) & !is.na(Sample_Size) &
                   Sample_Size > 999)

# Fit GLMM
glmm_Increasing_sens2 <- fit_glmm_prev(df_Increasing_sens2, "Increasing_n", "Sample_Size", "Sensitivity 2: N > 999")

# Display table
knitr::kable(glmm_Increasing_sens2, caption = "Sensitivity Analysis 2: Increasing Trajectory (Samples > 999)")
```

### Sensitivity Analysis 3

Exclude Influential Studies

```{r Increasing-influential}
# Fit a GLMM with glmer (binomial model with random study effect)
model_glmer_Increasing <- glmer(cbind(round(Increasing_n), Sample_Size - round(Increasing_n)) ~ 1 + (1 | Study),
                     data = df_Increasing,
                     family = binomial)

# Run influence analysis by Studies
infl <- influence(model_glmer_Increasing, group = "Study")

# Compute Cook's distance
cooks <- cooks.distance(infl)

# Define rule-of-thumb threshold
threshold <- 4 / length(cooks)

# Plot Cook's distances
p1 <- plot(cooks, type = "h", lwd = 2,
     main = "Cook's Distance per Study",
     ylab = "Cook's Distance", xlab = "Study Index")
abline(h = threshold, col = "red", lty = 2)

# Identify studies above the threshold
influential_indices <- which(cooks > threshold)
influential_studies_Increasing <- unique(df_Increasing$Study[influential_indices])

# Display studies
influential_table <- data.frame(
  Study_ID = influential_studies_Increasing,
  Cooks_Distance = round(cooks[influential_indices], 3)
)

knitr::kable(influential_table, caption = "Studies Identified as Influential (Cook's Distance)")
```

Excluding Influential Studies

```{r Increasing-sens-infl}
# Exclude the influential studies
df_Increasing_noinf <- df_Increasing %>%
  filter(!Study %in% influential_studies_Increasing)

# Refit GLMM (metafor version)
glmm_Increasing_noinf <- fit_glmm_prev(df_Increasing_noinf, "Increasing_n", "Sample_Size",
                           "Sensitivity 3: Excluding Influential Studies")

# Display table
knitr::kable(glmm_Increasing_noinf, caption = "Sensitivity Analysis 3: Increasing Trajectory (Excluding Influential Studies)")
```

### Use `glmer` estimate

Use with the glmer\`-based intercept estimate:

```{r Increasing-glmer-summary}
# Extract fixed effect estimate
est_glmer_Increasing <- fixef(model_glmer_Increasing)["(Intercept)"]
se_glmer_Increasing <- sqrt(vcov(model_glmer_Increasing)["(Intercept)", "(Intercept)"])

# Compute 95% CI (logit scale)
ci_Lower_glmer_Increasing <- est_glmer_Increasing - 1.96 * se_glmer_Increasing
ci_upper_glmer_Increasing <- est_glmer_Increasing + 1.96 * se_glmer_Increasing

n_glmer_studies_Increasing <- length(ranef(model_glmer_Increasing)$Study[[1]])

# Run glmer
glmer_summary_Increasing <- data.frame(
  Model = "glmer (binomial, random intercept)",
  Pooled_Prevalence = round(plogis(est_glmer_Increasing), 3),
  ci_Lower = round(plogis(ci_Lower_glmer_Increasing), 3),
  CI_Upper = round(plogis(ci_upper_glmer_Increasing), 3), 
  Studies_included = n_glmer_studies_Increasing
)

knitr::kable(glmer_summary_Increasing, caption = "Increasing Trajectory Estimate from glmer Model")
```

## 🩸 High Symptoms Trajectory

We estimate the pooled prevalence of the High trajectory using a Generalized Linear Mixed Model (GLMM).

### Descriptives

```{r High-descriptives}
# Copy the dataset to avoid overwriting the original
df_High <- df_moderation

# Ensure High_percentage is numeric
df_High$High_percentage <- as.numeric(df_High$High_percentage)


# Calculate High_n as (percentage / 100) * sample size
df_High$High_n <- round((df_High$High_percentage / 100) * df_High$Sample_Size)

# Total number of individuals classified as High (ignoring missingness in other variables)
total_High_n <- sum(df_High$High_n, na.rm = TRUE)

# Number of unique samples (assumes a column Study exists)
unique_High_studies <- length(unique(df_High$Study[!is.na(df_High$High_percentage)]))

# Display as a table
additional_info <- data.frame(
  Description = c("Total number of individuals in High trajectory", "Number of unique studies"),
  Value = format(c(total_High_n, unique_High_studies), big.mark = ",")
)

knitr::kable(additional_info, caption = "Additional Descriptives for High Trajectory Analysis")
```

### Generic GLMM

```{r High-glmm}
# Fit GLMM
glmm_High <- fit_glmm_prev(df_High, event_col = "High_n", n_col = "Sample_Size",
                             label = "Main Analysis")

# Display result
knitr::kable(glmm_High, caption = "Pooled Prevalence Estimate for High Trajectory (GLMM)")
```

### Sensitivity Analysis 1

Exclude Samples with ≥90% Decreasing Proportions

```{r High-sens1}
# Subset: Exclude samples with High trajectory ≥90% of the sample
df_High_sens1 <- subset(df_High,
                   !is.na(High_n) & !is.na(Sample_Size) &
                   !is.na(High_percentage) & High_percentage < 90)

# Fit GLMM
glmm_High_sens1 <-  fit_glmm_prev(df_High_sens1, "High_n", "Sample_Size", "Sensitivity 1: Exclude ≥90% High")

# Display table
knitr::kable(glmm_High_sens1, caption = "Sensitivity Analysis 1: High Trajectory (Excl. ≥90% Prevalence)")
```

### Sensitivity Analysis 2

Include Only Samples with N \> 999

```{r High-sens2}
# Subset: Include only samples with Sample_Size > 999
df_High_sens2 <- subset(df_High,
                   !is.na(High_n) & !is.na(Sample_Size) &
                   Sample_Size > 999)

# Fit GLMM
glmm_High_sens2 <- fit_glmm_prev(df_High_sens2, "High_n", "Sample_Size", "Sensitivity 2: N > 999")

# Display table
knitr::kable(glmm_High_sens2, caption = "Sensitivity Analysis 2: High Trajectory (Samples > 999)")
```

### Sensitivity Analysis 3

Exclude Influential Studies

```{r High-influential}
# Fit a GLMM with glmer (binomial model with random study effect)
model_glmer_High <- glmer(cbind(round(High_n), Sample_Size - round(High_n)) ~ 1 + (1 | Study),
                     data = df_High,
                     family = binomial)

# Run influence analysis by Studies
infl <- influence(model_glmer_High, group = "Study")

# Compute Cook's distance
cooks <- cooks.distance(infl)

# Define rule-of-thumb threshold
threshold <- 4 / length(cooks)

# Plot Cook's distances
p1 <- plot(cooks, type = "h", lwd = 2,
     main = "Cook's Distance per Study",
     ylab = "Cook's Distance", xlab = "Study Index")
abline(h = threshold, col = "red", lty = 2)

# Identify studies above the threshold
influential_indices <- which(cooks > threshold)
influential_studies_High <- unique(df_High$Study[influential_indices])

# Display studies
influential_table <- data.frame(
  Study_ID = influential_studies_High,
  Cooks_Distance = round(cooks[influential_indices], 3)
)

knitr::kable(influential_table, caption = "Studies Identified as Influential (Cook's Distance)")
```

Exclude Influential Studies

```{r High-sens-infl}
# Exclude the influential studies
df_High_noinf <- df_High %>%
  filter(!Study %in% influential_studies_High)

# Refit GLMM (metafor version)
glmm_High_noinf <- fit_glmm_prev(df_High_noinf, "High_n", "Sample_Size",
                           "Sensitivity 3: Excluding Influential Studies")

# Display table
knitr::kable(glmm_High_noinf, caption = "Sensitivity Analysis 3: High Trajectory (Excluding Influential Studies)")
```

### Use `glmer`estimate

Use with the glmer\`-based intercept estimate:

```{r High-glmer-summary}
# Extract fixed effect estimate
est_glmer_High <- fixef(model_glmer_High)["(Intercept)"]
se_glmer_High <- sqrt(vcov(model_glmer_High)["(Intercept)", "(Intercept)"])

# Compute 95% CI (logit scale)
ci_Lower_glmer_High <- est_glmer_High - 1.96 * se_glmer_High
ci_upper_glmer_High <- est_glmer_High + 1.96 * se_glmer_High

n_glmer_studies_High <- length(ranef(model_glmer_High)$Study[[1]])

# Run glmer
glmer_summary_High <- data.frame(
  Model = "glmer (binomial, random intercept)",
  Pooled_Prevalence = round(plogis(est_glmer_High), 3),
  ci_Lower = round(plogis(ci_Lower_glmer_High), 3),
  CI_Upper = round(plogis(ci_upper_glmer_High), 3), 
  Studies_included = n_glmer_studies_High
)

knitr::kable(glmer_summary_High, caption = "High Trajectory Estimate from glmer Model")
```

## 🌗 Moderate Symptoms Trajectory

We estimate the pooled prevalence of the Moderate trajectory using a Generalized Linear Mixed Model (GLMM)

### Descriptives

```{r moderate-descriptives}
# Copy the dataset to avoid overwriting the original
df_Moderate <- df_moderation

# Ensure Moderate_percentage is numeric
df_Moderate$Moderate_percentage <- as.numeric(df_Moderate$Moderate_percentage)


# Calculate Moderate_n as (percentage / 100) * sample size
df_Moderate$Moderate_n <- round((df_Moderate$Moderate_percentage / 100) * df_Moderate$Sample_Size)

# Total number of individuals classified as Moderate (ignoring missingness in other variables)
total_Moderate_n <- sum(df_Moderate$Moderate_n, na.rm = TRUE)

# Number of unique samples (assumes a column Study exists)
unique_Moderate_studies <- length(unique(df_Moderate$Study[!is.na(df_Moderate$Moderate_percentage)]))

# Display as a table
additional_info <- data.frame(
  Description = c("Total number of individuals in Moderate trajectory", "Number of unique studies"),
  Value = format(c(total_Moderate_n, unique_Moderate_studies), big.mark = ",")
)

knitr::kable(additional_info, caption = "Additional Descriptives for Moderate Trajectory Analysis")
```

### Generic GLMM

```{r moderate-glmm}
# Fit GLMM
glmm_Moderate <- fit_glmm_prev(df_Moderate, event_col = "Moderate_n", n_col = "Sample_Size",
                             label = "Main Analysis")

# Display result
knitr::kable(glmm_Moderate, caption = "Pooled Prevalence Estimate for Moderate Trajectory (GLMM)")
```

### Sensitivity Analysis 1

Exclude Samples with ≥90% Prevalence

```{r moderate-sens1}
# Subset: Exclude samples with Moderate trajectory ≥90% of the sample
df_Moderate_sens1 <- subset(df_Moderate,
                   !is.na(Moderate_n) & !is.na(Sample_Size) &
                   !is.na(Moderate_percentage) & Moderate_percentage < 90)

# Fit GLMM
glmm_Moderate_sens1 <-  fit_glmm_prev(df_Moderate_sens1, "Moderate_n", "Sample_Size", "Sensitivity 1: Exclude ≥90% Moderate")

# Display table
knitr::kable(glmm_Moderate_sens1, caption = "Sensitivity Analysis 1: Moderate Trajectory (Excl. ≥90% Prevalence)")
```

### Sensitivity Analysis 2

Only Large Samples (N \> 999)

```{r moderate-sens2}
# Subset: Include only samples with Sample_Size > 999
df_Moderate_sens2 <- subset(df_Moderate,
                   !is.na(Moderate_n) & !is.na(Sample_Size) &
                   Sample_Size > 999)

# Fit GLMM
glmm_Moderate_sens2 <- fit_glmm_prev(df_Moderate_sens2, "Moderate_n", "Sample_Size", "Sensitivity 2: N > 999")

# Display table
knitr::kable(glmm_Moderate_sens2, caption = "Sensitivity Analysis 2: Moderate Trajectory (Samples > 999)")
```

### Sensitivity Analysis 3

Exclude Influential Studies

```{r moderate-influential}
# Fit a GLMM with glmer (binomial model with random study effect)
model_glmer_Moderate <- glmer(cbind(round(Moderate_n), Sample_Size - round(Moderate_n)) ~ 1 + (1 | Study),
                     data = df_Moderate,
                     family = binomial)

# Run influence analysis by Studies
infl <- influence(model_glmer_Moderate, group = "Study")

# Compute Cook's distance
cooks <- cooks.distance(infl)

# Define rule-of-thumb threshold
threshold <- 4 / length(cooks)

# Plot Cook's distances
p1 <- plot(cooks, type = "h", lwd = 2,
     main = "Cook's Distance per Study",
     ylab = "Cook's Distance", xlab = "Study Index")
abline(h = threshold, col = "red", lty = 2)

# Identify studies above the threshold
influential_indices <- which(cooks > threshold)
influential_studies_Moderate <- unique(df_Moderate$Study[influential_indices])

# Display studies
influential_table <- data.frame(
  Study_ID = influential_studies_Moderate,
  Cooks_Distance = round(cooks[influential_indices], 3)
)

knitr::kable(influential_table, caption = "Studies Identified as Influential (Cook's Distance)")
```

Refit Model Excluding Influential Studies

```{r moderate-sens-infl}
# Exclude the influential studies
df_Moderate_noinf <- df_Moderate %>%
  filter(!Study %in% influential_studies_Moderate)

# Refit GLMM (metafor version)
glmm_Moderate_noinf <- fit_glmm_prev(df_Moderate_noinf, "Moderate_n", "Sample_Size",
                           "Sensitivity 3: Excluding Influential Studies")

# Display table
knitr::kable(glmm_Moderate_noinf, caption = "Sensitivity Analysis 3: Moderate Trajectory (Excluding Influential Studies)")
```

### Use `glmer`estimate

```{r moderate-glmer-summary}
# Extract fixed effect estimate
est_glmer_Moderate <- fixef(model_glmer_Moderate)["(Intercept)"]
se_glmer_Moderate <- sqrt(vcov(model_glmer_Moderate)["(Intercept)", "(Intercept)"])

# Compute 95% CI (logit scale)
ci_Lower_glmer_Moderate <- est_glmer_Moderate - 1.96 * se_glmer_Moderate
ci_upper_glmer_Moderate <- est_glmer_Moderate + 1.96 * se_glmer_Moderate

n_glmer_studies_Moderate <- length(ranef(model_glmer_Moderate)$Study[[1]])

# Run glmer
glmer_summary_Moderate <- data.frame(
  Model = "glmer (binomial, random intercept)",
  Pooled_Prevalence = round(plogis(est_glmer_Moderate), 3),
  ci_Lower = round(plogis(ci_Lower_glmer_Moderate), 3),
  CI_Upper = round(plogis(ci_upper_glmer_Moderate), 3), 
  Studies_included = n_glmer_studies_Moderate
)

knitr::kable(glmer_summary_Moderate, caption = "Moderate Trajectory Estimate from glmer Model")
```

# Tables for Paper
## Prevalences Summary Table

```{r prevalences-summary-table, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# Trajectory specification
traj_specs <- tibble::tribble(
  ~trajectory,  ~perc_col,             ~event_col,
  "Low",        "Low_percentage",      "Low_n",
  "Decreasing", "Decreasing_percentage","Decreasing_n",
  "Increasing", "Increasing_percentage","Increasing_n",
  "High",       "High_percentage",     "High_n",
  "Moderate",   "Moderate_percentage", "Moderate_n"
)

# build a per-trajectory analysis frame & run GLMM
build_and_fit <- function(df, perc_col, event_col, label = perc_col) {
  df <- df %>% mutate(
    !!perc_col := as.numeric(.data[[perc_col]]),
    !!event_col := round((.data[[perc_col]] / 100) * .data[["Sample_Size"]])
  )

  # Counts for N and k
  total_n <- sum(df[[event_col]], na.rm = TRUE)
  k_unique <- length(unique(df$Study[!is.na(df[[perc_col]])]))

  # Run your portable GLMM (uses your new function)
  fit_row <- fit_glmm_prev(df, event_col = event_col, n_col = "Sample_Size", label = label)

  list(
    df = df,
    total_n = total_n,
    k = k_unique,
    fit = fit_row
  )
}

# analyses for all trajectories 
analyses <- traj_specs %>%
  rowwise() %>%
  mutate(res = list(build_and_fit(df_moderation, perc_col, event_col, trajectory))) %>%
  ungroup()

# totals for N (%) 
totals <- analyses %>%
  mutate(N = purrr::map_dbl(res, "total_n")) %>%     # <-- ensure a numeric vector
  transmute(
    trajectory = factor(trajectory, levels = traj_specs$trajectory),
    N
  ) %>%
  mutate(pct = round(100 * N / sum(N, na.rm = TRUE), 1))

# Extract model rows & assemble final table data
fits_df <- analyses %>%
  mutate(
    k   = purrr::map_int(res, "k"),             
    fit = purrr::map(res, "fit")
  ) %>%
  select(trajectory, k, fit) %>%
  tidyr::unnest_wider(fit) %>%
  transmute(
    trajectory,
    rel_prev = sprintf("%.1f%%", 100 * Pooled_Prevalence),
    ci_95    = sprintf("%.1f to %.1f%%", 100 * CI_Lower, 100 * CI_Upper),
    k        = as.integer(k),
    logit    = round(Logit_Estimate, 2),
    tau2     = round(`τ2`, 2)
  )


# Join counts and format N (%)
table1_df <- fits_df %>%
  left_join(totals, by = "trajectory") %>%
  transmute(
    trajectory,
    rel_prev,
    ci_95,
    k,
    N_pct = sprintf("%s (%.1f%%)", format(N, big.mark = ","), pct),
    logit,
    tau2
  ) %>%
  arrange(factor(trajectory, levels = traj_specs$trajectory))

# Render with gt
tbl1 <- table1_df |>
  gt() |>
  cols_label(
    trajectory = "PTSD Symptom Trajectory",
    rel_prev   = "Relative Prevalence",
    ci_95      = "95% (CI)",
    k          = html("<em>k</em>"),
    N_pct      = "N (%)",
    logit      = "Logit Estimate",
    tau2       = html("<em>&tau;<sup>2</sup></em>")
  ) |>
  cols_align("left",   columns = trajectory) |>
  cols_align("center", columns = c(rel_prev, ci_95, k, N_pct, logit, tau2)) |>
  fmt_integer(columns = k, use_seps = TRUE) |>
  fmt_number(columns = c(logit, tau2), decimals = 2) |>
  opt_row_striping() |>
  tab_style(
    style = cell_text(size = px(11), font = "Times New Roman"),
    locations = cells_source_notes()
  ) |>
  tab_options(
    table.width = pct(100),
    data_row.padding = px(6),
    table.font.size = px(13),
    table.font.names = "Times New Roman",
    column_labels.font.weight = "bold"
  ) |>
  tab_source_note(
    source_note = html("<em>Note.</em> <em>k</em> represents the number of unique samples. Logit estimate reflects pooled prevalence on a log-odds scale. <em>&tau;<sup>2</sup></em> indicates between-study heterogeneity; values &gt; 0.50 suggest substantial heterogeneity.")
  ) |>
  tab_style(
    style = cell_text(size = px(11)),
    locations = cells_source_notes()
  ) |>
  opt_table_font(
    font = list(
      google_font("Times New Roman"),
      default_fonts()
    )
  )

tbl1

# Optional exports
gt::gtsave(tbl1, "prevalences-summary-table.png", vwidth = 700)
gt::gtsave(tbl1, "prevalences-summary-table.rtf")
```

## Sensitivity Analyses Summary

```{r sensitivity-summary-table, message=FALSE, warning=FALSE}
mk_row_df <- function(res_df, label) {
  # res_df is the one-row data.frame returned by fit_glmm_prev()
  r <- res_df[1, , drop = FALSE]
  tibble(
    Analysis = label,
    k        = as.integer(r$Samples_included),
    `Relative Prevalence (95% CI)` =
      sprintf("%.1f%% [%.1f%% – %.1f%%]",
              100 * as.numeric(r$Pooled_Prevalence),
              100 * as.numeric(r$CI_Lower),
              100 * as.numeric(r$CI_Upper)),
    `Logit Estimate` = as.numeric(r$Logit_Estimate),
    tau2             = suppressWarnings(as.numeric(r$`τ2`))
  )
}

# Labels / mappings
trajectory_map <- c(
  "Low"        = "Low symptoms",
  "Decreasing" = "Decreasing symptoms",
  "Increasing" = "Increasing symptoms",
  "High"       = "High symptoms",
  "Moderate"   = "Moderate symptoms"
)

analysis_map <- c(
  "Main"  = "Main analysis (all studies)",
  "sens1" = "Excluding studies with extreme prevalence (≥90%)",
  "sens2" = "Including only large-sample studies (N ≥ 1000)",
  "noinf" = "Excluding influential studies"
)

# Build the spec of objects to look up (glmm_<traj>[_<stub>])
all_specs <- tidyr::crossing(
  trajectory_stub = names(trajectory_map),
  analysis_stub   = names(analysis_map)
) |>
  mutate(
    object_name = if_else(
      analysis_stub == "Main",
      paste0("glmm_", trajectory_stub),
      paste0("glmm_", trajectory_stub, "_", analysis_stub)
    ),
    Trajectory = trajectory_map[trajectory_stub],
    Analysis   = analysis_map[analysis_stub]
  )

# Build the table by reading the one-row data.frames created earlier
big_tbl <- purrr::pmap_dfr(
  all_specs,
  function(object_name, Trajectory, Analysis, ...) {
    obj <- tryCatch(get(object_name, envir = .GlobalEnv), error = \(e) NULL)
    if (!is.null(obj) && is.data.frame(obj) && nrow(obj) >= 1) {
      mk_row_df(obj, Analysis) |> mutate(Trajectory = Trajectory, .before = 1)
    }
  }
)

# Enforce display order
trajectory_order <- c(
  "Low symptoms",
  "Decreasing symptoms",
  "Increasing symptoms",
  "High symptoms",
  "Moderate symptoms"
)

big_tbl_ordered <- big_tbl |>
  mutate(Trajectory = factor(Trajectory, levels = trajectory_order)) |>
  arrange(Trajectory)

# Create gt table
gt_all <-
  gt(big_tbl_ordered, groupname_col = "Trajectory") |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_row_groups()
  ) |>
  cols_label(
    Analysis = "Analysis",
    k = html("<em>k</em>"),
    `Relative Prevalence (95% CI)` = "Relative Prevalence (95% CI)",
    `Logit Estimate` = "Logit Estimate",
    tau2 = html("<em>&tau;<sup>2</sup></em>")
  ) |>
  fmt_number(columns = c(`Logit Estimate`, tau2), decimals = 2) |>
  cols_align(align = "left", columns = Analysis) |>
  cols_align(align = "center", columns = c(k, `Relative Prevalence (95% CI)`, `Logit Estimate`, tau2)) |>
  opt_row_striping() |>
  tab_options(
    table.font.names = c("Times New Roman", "Times", "serif"),
    data_row.padding = px(6),
    column_labels.font.weight = "bold",
    row_group.as_column = FALSE,
    table.font.size = px(13)
  ) |>
  tab_style(
    style = cell_text(size = px(11), font = "Times New Roman"),
    locations = list(cells_source_notes(), cells_footnotes())
  ) |>
  tab_source_note(md(
    "<em>Note.</em> <em>k</em> represents the number of unique samples. Logit estimate reflects pooled prevalence on a log-odds scale. <em>&tau;<sup>2</sup></em> indicates between-study heterogeneity; values &gt; 0.50 suggest substantial heterogeneity."
  ))

# Footnotes for excluded influential studies 
.influential_for <- function(traj_stub) {
  nm <- paste0("influential_studies_", traj_stub)
  v  <- tryCatch(get(nm, envir = .GlobalEnv), error = \(e) NULL)
  if (is.null(v)) character(0) else as.character(v)
}
format_note <- function(vec) {
  if (length(vec) == 0) "No influential studies excluded."
  else paste0("Excluded influential studies: ", paste(vec, collapse = "; "))
}

excluded_by_group <- setNames(
  lapply(names(trajectory_map), .influential_for),
  nm = unname(trajectory_map[names(trajectory_map)])
)
excluded_notes <- lapply(excluded_by_group, format_note)

# add notes to table
gt_all <- purrr::reduce(
  names(excluded_notes),
  .init = gt_all,
  .f = function(gt_obj, grp_label) {
    tab_footnote(
      gt_obj,
      footnote  = excluded_notes[[grp_label]],
      locations = cells_body(
        columns = "Analysis",
        rows = (Trajectory == grp_label) & (Analysis == "Excluding influential studies")
      )
    )
  }
)

gt_all

# Exports
gt::gtsave(gt_all, "prevalences-sensitivity-table.rtf")
gt::gtsave(gt_all, "prevalences-sensitivity-table.png", vwidth = 700)

```












